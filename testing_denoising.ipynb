{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c8fb10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from denodas_model import unet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "print(torch.cuda.device_count())\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d425e6",
   "metadata": {},
   "source": [
    "Trying the model on small, fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b77fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input parameters\n",
    "# batch_size = 1\n",
    "# ch_in = 1\n",
    "# height = 256\n",
    "# width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c17c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a base seismic wave pattern\n",
    "# x = np.linspace(0, 4 * np.pi, width)  # Simulate time axis\n",
    "# seismic_signal = np.sin(x) + np.sin(2*x) * 0.5 + np.sin(3*x) * 0.3  # Combination of sine waves\n",
    "\n",
    "# # Create a 2D wave pattern by stacking with varying amplitude\n",
    "# seismic_data = np.zeros((height, width))\n",
    "# for i in range(height):\n",
    "#     amp = np.exp(-0.02 * (i - height//2)**2)  # Gaussian envelope to mimic seismic arrivals\n",
    "#     seismic_data[i, :] = amp * seismic_signal\n",
    "\n",
    "# # Add random Gaussian noise\n",
    "# noise = np.random.normal(0, 0.2, (height, width))  # Adjust noise level as needed\n",
    "# seismic_data_noisy = seismic_data + noise\n",
    "\n",
    "# # Normalize to [-1, 1] for better input to model\n",
    "# seismic_data_noisy = seismic_data_noisy / np.max(np.abs(seismic_data_noisy))\n",
    "\n",
    "# # Expand to (batch_size, ch_in, height, width) for model input\n",
    "# sample_numpy_input = seismic_data_noisy[np.newaxis, np.newaxis, :, :]\n",
    "\n",
    "# # Display the generated noisy seismic data\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(seismic_data_noisy, aspect='auto', cmap='seismic', interpolation='none')\n",
    "# plt.colorbar(label=\"Amplitude\")\n",
    "# plt.title(\"Simulated Noisy Seismic Data\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Sensor Channels\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e742c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_tensor_input = torch.tensor(sample_numpy_input, dtype=torch.float32)\n",
    "# print(\"Converted Tensor Shape:\", sample_tensor_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c51af3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define U-Net parameters\n",
    "# ch_in = 64      # Number of input channels\n",
    "# ch0 = 16        # Initial number of feature maps\n",
    "# ch_max = 64     # Maximum number of feature maps\n",
    "# factors = [2, 2, 2, 2]  # Downsampling factors (4 levels)\n",
    "\n",
    "# # Initialize model\n",
    "# model = unet(ch_in, ch0, ch_max, factors=factors)\n",
    "\n",
    "# # Ensure model is in evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Pass the noisy seismic data through the model\n",
    "# output = model(sample_tensor_input)\n",
    "\n",
    "# # Convert output back to NumPy for visualization\n",
    "# output_numpy = output.detach().numpy().squeeze()  # Remove batch & channel dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66a5e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot results\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# # Noisy input\n",
    "# axes[0].imshow(seismic_data_noisy, aspect='auto', cmap='seismic', interpolation='none')\n",
    "# axes[0].set_title(\"Noisy Seismic Data\")\n",
    "# axes[0].set_xlabel(\"Time\")\n",
    "# axes[0].set_ylabel(\"Sensor Channels\")\n",
    "\n",
    "# # Denoised output\n",
    "# axes[1].imshow(output_numpy, aspect='auto', cmap='seismic', interpolation='none')\n",
    "# axes[1].set_title(\"Denoised Seismic Data (U-Net Output)\")\n",
    "# axes[1].set_xlabel(\"Time\")\n",
    "# axes[1].set_ylabel(\"Sensor Channels\")\n",
    "\n",
    "# plt.colorbar(axes[0].imshow(seismic_data_noisy, aspect='auto', cmap='seismic'), ax=axes[0])\n",
    "# plt.colorbar(axes[1].imshow(output_numpy, aspect='auto', cmap='seismic'), ax=axes[1])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "586b2985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 8531)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(os.path.join(\"test_data\", \"11707158.npy\"))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb7e3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Tensor Shape: torch.Size([3000, 8531])\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "print(\"Converted Tensor Shape:\", data_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "866bdedb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 375 but got size 374 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Pass the noisy seismic data through the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert output back to NumPy for visualization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m output_numpy \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Remove batch & channel dimensions\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/curatedDAS/denodas_model.py:106\u001b[0m, in \u001b[0;36munet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     cat \u001b[38;5;241m=\u001b[39m cat_content[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m--> 106\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer[st_lvl \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m](x)  \u001b[38;5;66;03m# conv2\u001b[39;00m\n\u001b[1;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 375 but got size 374 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Define U-Net parameters\n",
    "ch_in = 1    # Number of input channels\n",
    "ch0 = 16        # Initial number of feature maps\n",
    "ch_max = 64     # Maximum number of feature maps\n",
    "factors = [2, 2, 2, 2]  # Downsampling factors (4 levels)\n",
    "\n",
    "# Initialize model\n",
    "model = unet(ch_in, ch0, ch_max, factors=factors)\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Pass the noisy seismic data through the model\n",
    "output = model(data_tensor)\n",
    "\n",
    "# Convert output back to NumPy for visualization\n",
    "output_numpy = output.detach().numpy().squeeze()  # Remove batch & channel dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9292402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
